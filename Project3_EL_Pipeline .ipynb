{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import psycopg2\n",
    "\n",
    "# define a connection string to Access database\n",
    "conn_str = (\n",
    "    r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};'\n",
    "    r'DBQ=C:\\Users\\23470\\OneDrive\\Desktop\\10Alytics\\capstone_project\\project3\\WPI.accdb;'\n",
    "    )\n",
    "conn = pyodbc.connect(conn_str)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# retrieve table names from the Access database\n",
    "table_names = [table.table_name for table in cursor.tables(tableType='TABLE')]\n",
    "\n",
    "# save tables to csv file on local machine\n",
    "for table_name in table_names:\n",
    "    df = pd.read_sql_query(f'SELECT * FROM [{table_name}]', conn)\n",
    "    df.to_csv(f'{table_name.replace(\"/\", \"_\")}.csv', index=False)\n",
    "    \n",
    "# closs connection \n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a connect to postgres sever \n",
    "def get_db_connection(host, database, username, password):\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        database=database,\n",
    "        user=username,\n",
    "        password=password\n",
    "    )\n",
    "    \n",
    "    return conn\n",
    "\n",
    "# initialize connection function parameters\n",
    "host = \"localhost\"\n",
    "database = \"World_Port_index\"\n",
    "username = \"postgres\"\n",
    "password = \"kw#s#k00\"\n",
    "\n",
    "# establish a connect\n",
    "con = get_db_connection(host, database, username, password)\n",
    "# create cursor\n",
    "curr = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the csv file of the Wpi Data to a dataframe for easy upload to postgres database\n",
    "ndf = pd.read_csv('Wpi Data.csv')\n",
    "ndf = pd.DataFrame(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the dataframe to postgress database\n",
    "# NB: a database called World_Port_index and table name wpi_data has already been created in postgres server \n",
    "with open('Wpi Data.csv', 'r') as file:\n",
    "    next(file)  # Skip the header row if needed\n",
    "\n",
    "    # Use the COPY statement to upload the data\n",
    "    curr.copy_from(file, 'wpi_data', sep=',')\n",
    "    con.commit()\n",
    "    \n",
    "# close connection   \n",
    "curr.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
